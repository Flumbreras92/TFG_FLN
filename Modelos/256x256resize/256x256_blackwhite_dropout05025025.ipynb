{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ongoing-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Flatten, Dense, Dropout,  Activation, Conv3D, MaxPooling3D, UpSampling3D, BatchNormalization, Activation, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "#from keras.utils import multi_gpu_model\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.merge import concatenate, add\n",
    "\n",
    "#from keras.utils.io_utils import HDF5Matrix\n",
    "from keras.utils import plot_model\n",
    "from keras import optimizers\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "organic-unemployment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 8, 256, 256, 1)]  0         \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              (None, 8, 256, 256, 8)    1008      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 8, 256, 256, 8)    32        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 8, 256, 256, 8)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 256, 256, 8)    32        \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 2, 32, 32, 8)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2, 32, 32, 8)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 2, 32, 32, 16)     16016     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 2, 32, 32, 16)     64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2, 32, 32, 16)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 2, 32, 32, 16)     64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 1, 8, 8, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 8, 8, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 1, 8, 8, 32)       64032     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1, 8, 8, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1, 8, 8, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1, 8, 8, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 1, 4, 4, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 4, 4, 32)       0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 82,530\n",
      "Trainable params: 82,306\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def conv3d_block(input_tensor, filters, kernel_size, activation_fun = \"linear\"):\n",
    "    # first layer\n",
    "    x = Conv3D(filters=filters, kernel_size=kernel_size, kernel_initializer=\"he_normal\", padding=\"same\")(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation_fun)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "kernel_size = (5,5,5)\n",
    "act_fun = \"relu\"\n",
    "\n",
    "############### DEFINE SET OF INPUTS #################\n",
    "\n",
    "x = Input(shape=(8, 256, 256,1)) \n",
    "\n",
    "\n",
    "############## DEFINE PATH FOR INPUT 1 ##################\n",
    "\n",
    "\n",
    "c1 = conv3d_block (x, filters=8, kernel_size=kernel_size, activation_fun = act_fun )\n",
    "c1 = BatchNormalization()(c1)\n",
    "p1 = MaxPooling3D (pool_size=(4, 8, 8), padding='valid')(c1)\n",
    "p1 = Dropout(0.5)(p1)\n",
    "\n",
    "\n",
    "c2 = conv3d_block(p1, filters=16, kernel_size=kernel_size, activation_fun = act_fun )\n",
    "c2 = BatchNormalization()(c2)\n",
    "p2 = MaxPooling3D(pool_size=(2, 4, 4), padding='valid')(c2)\n",
    "p2 = Dropout(0.25)(p2)\n",
    "\n",
    "\n",
    "c3 = conv3d_block(p2, filters=32, kernel_size=kernel_size, activation_fun = act_fun )\n",
    "c3 = BatchNormalization()(c3)\n",
    "p3 = MaxPooling3D(pool_size=(1, 2, 2), padding='valid')(c3)\n",
    "p3 = Dropout(0.25)(p3)\n",
    "\n",
    "\n",
    "p3 = Reshape((512,))(p3)\n",
    "\n",
    "\n",
    "d = Dense(2, activation = 'sigmoid')(p3)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(x , d)\n",
    "model.compile(optimizer=\"Adam\", loss=tf.keras.losses.BinaryCrossentropy())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lonely-report",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cm/shared/apps/anaconda2/4.3.1/envs/jupyter3.7/lib/python3.7/site-packages/ipykernel_launcher.py:6: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, Directorio, batch_size = 5):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.Directorio = h5py.File(Directorio)\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return int((len(self.Directorio)/2) / self.batch_size)\n",
    "\n",
    "    \n",
    "    #Getitem nos devolvera los valores de X e Y para el indice de batch que le pida keras\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        #Creamos dos listas vacias en las que se separaran los valores de X e Y de nuestro archivo\n",
    "        array_x = []\n",
    "        array_y = []\n",
    "        \n",
    "        #Numero de ejemplos que tenemos en nuestro dataset, dividimos entre dos por que la longitud total\n",
    "        #viene con el numero de X e Y\n",
    "        self.indexes = np.arange(int(len(self.Directorio)/2))\n",
    "        \n",
    "        #dependiendo del indice de batch, indexes nos dara la posicion de los datos que queremos extraer\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        #Recorremos el directorio y extraemos las X con sus frames y las Y con sus estados\n",
    "        for line in self.Directorio:\n",
    "\n",
    "            if line[0] == 'X':\n",
    "                array_x.append(self.Directorio[line])\n",
    "\n",
    "            if line [0] == 'Y':\n",
    "                array_y.append(self.Directorio[line])\n",
    "        \n",
    "        #dos nuevos listas en las que almacenaremos los datos correspondientes a las posiciones que nos pide\n",
    "        #el indice del batch\n",
    "        x = []\n",
    "        y = []\n",
    "        \n",
    "        for i in indexes:\n",
    "            x.append(array_x[i])\n",
    "            y.append(array_y[i])\n",
    "        \n",
    "        #convertimos la lista anterior en un array con shape (batch_size,8,512,512,3)\n",
    "        x_array = np.array(x)\n",
    "        \n",
    "        \n",
    "        #Keras no entiende de strings, por lo que pasamos esos strings a vectores con numeros\n",
    "        RE = [1,0] #vector para estado: reposo\n",
    "        EA = [0,1] #vector para estado: ataque\n",
    "        \n",
    "        #lista donde almacenamos los vectores asociados a su string correspondiente\n",
    "        y_strings = []\n",
    "        \n",
    "        for i in y:\n",
    "\n",
    "            if i.value == 'RE':\n",
    "                y_strings.append(RE)\n",
    "\n",
    "            else:\n",
    "                y_strings.append(EA)\n",
    "                \n",
    "        #convertimos la lista anterior en un array con shape (batch_size,2)\n",
    "        y_array = np.array(y_strings)\n",
    "\n",
    "        X, y = x_array,y_array\n",
    "\n",
    "        return X,y\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "\n",
    "train_samples =  '/mnt/MD1200A/lconcha/videos/256x256/Datasets_training_256/Combinado_training_group32_256_blackwhite'\n",
    "test_samples =  '/mnt/MD1200A/lconcha/videos/256x256/Datasets_training_256/Combinado_validation_group32_256_2_blackwhite'\n",
    "\n",
    "training_generator   = DataGenerator(train_samples, batch_size )\n",
    "validation_generator = DataGenerator(test_samples,  batch_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-government",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cm/shared/apps/anaconda2/4.3.1/envs/jupyter3.7/lib/python3.7/site-packages/ipykernel_launcher.py:16: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  app.launch_new_instance()\n",
      "/cm/shared/apps/anaconda2/4.3.1/envs/jupyter3.7/lib/python3.7/site-packages/ipykernel_launcher.py:21: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "/cm/shared/apps/anaconda2/4.3.1/envs/jupyter3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "/cm/shared/apps/anaconda2/4.3.1/envs/jupyter3.7/lib/python3.7/site-packages/ipykernel_launcher.py:58: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "15/15 [==============================] - 2408s 160s/step - loss: 0.9378 - accuracy: 0.5474 - val_loss: 1.4303 - val_accuracy: 0.5130\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 2406s 160s/step - loss: 0.7864 - accuracy: 0.6122 - val_loss: 0.8487 - val_accuracy: 0.5780\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 2394s 160s/step - loss: 0.7442 - accuracy: 0.6262 - val_loss: 0.7228 - val_accuracy: 0.5860\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 2384s 159s/step - loss: 0.7109 - accuracy: 0.6595 - val_loss: 0.6576 - val_accuracy: 0.6550\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 2400s 160s/step - loss: 0.6869 - accuracy: 0.6555 - val_loss: 0.6793 - val_accuracy: 0.6010\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 2409s 161s/step - loss: 0.6711 - accuracy: 0.6654 - val_loss: 0.6618 - val_accuracy: 0.6240\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 2405s 160s/step - loss: 0.6465 - accuracy: 0.6859 - val_loss: 0.6332 - val_accuracy: 0.6640\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 2403s 160s/step - loss: 0.6523 - accuracy: 0.6651 - val_loss: 0.6473 - val_accuracy: 0.6200\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 2402s 160s/step - loss: 0.6401 - accuracy: 0.6756 - val_loss: 0.6304 - val_accuracy: 0.6530\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 2394s 160s/step - loss: 0.6369 - accuracy: 0.6790 - val_loss: 0.6270 - val_accuracy: 0.6380\n",
      "\n",
      "Epoch 00010: saving model to /mnt/MD1200A/lconcha/videos/Modelos/256x256_blackwhite_dropout_00500250025/training/cp.ckpt\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 2392s 160s/step - loss: 0.6264 - accuracy: 0.6917 - val_loss: 0.6663 - val_accuracy: 0.5380\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 2401s 160s/step - loss: 0.6243 - accuracy: 0.6880 - val_loss: 0.6429 - val_accuracy: 0.6580\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 2409s 161s/step - loss: 0.6107 - accuracy: 0.6866 - val_loss: 0.6188 - val_accuracy: 0.7120\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 2396s 160s/step - loss: 0.6124 - accuracy: 0.6885 - val_loss: 0.6062 - val_accuracy: 0.7250\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 2422s 162s/step - loss: 0.6009 - accuracy: 0.7100 - val_loss: 0.6103 - val_accuracy: 0.7300\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 2441s 163s/step - loss: 0.5918 - accuracy: 0.7092 - val_loss: 0.6147 - val_accuracy: 0.6970\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 2866s 193s/step - loss: 0.6048 - accuracy: 0.6982 - val_loss: 0.6084 - val_accuracy: 0.7060\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 2438s 163s/step - loss: 0.5897 - accuracy: 0.7190 - val_loss: 0.5978 - val_accuracy: 0.7220\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 2393s 160s/step - loss: 0.5842 - accuracy: 0.7098 - val_loss: 0.6097 - val_accuracy: 0.6810\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 2391s 160s/step - loss: 0.5767 - accuracy: 0.7238 - val_loss: 0.5812 - val_accuracy: 0.7400\n",
      "\n",
      "Epoch 00020: saving model to /mnt/MD1200A/lconcha/videos/Modelos/256x256_blackwhite_dropout_00500250025/training/cp.ckpt\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 2385s 159s/step - loss: 0.5478 - accuracy: 0.7376 - val_loss: 0.5680 - val_accuracy: 0.7450\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 2397s 160s/step - loss: 0.5783 - accuracy: 0.7130 - val_loss: 0.5625 - val_accuracy: 0.7390\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 2390s 160s/step - loss: 0.5595 - accuracy: 0.7337 - val_loss: 0.5554 - val_accuracy: 0.7570\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 2395s 160s/step - loss: 0.5711 - accuracy: 0.7330 - val_loss: 0.5598 - val_accuracy: 0.7350\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 2391s 159s/step - loss: 0.5646 - accuracy: 0.7235 - val_loss: 0.5694 - val_accuracy: 0.7190\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 2404s 161s/step - loss: 0.5520 - accuracy: 0.7208 - val_loss: 0.5584 - val_accuracy: 0.7280\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 2390s 159s/step - loss: 0.5466 - accuracy: 0.7364 - val_loss: 0.5415 - val_accuracy: 0.7640\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 2396s 160s/step - loss: 0.5591 - accuracy: 0.7301 - val_loss: 0.5433 - val_accuracy: 0.7580\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 2405s 160s/step - loss: 0.5461 - accuracy: 0.7455 - val_loss: 0.5486 - val_accuracy: 0.7150\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 2405s 160s/step - loss: 0.5490 - accuracy: 0.7293 - val_loss: 0.5406 - val_accuracy: 0.7460\n",
      "\n",
      "Epoch 00030: saving model to /mnt/MD1200A/lconcha/videos/Modelos/256x256_blackwhite_dropout_00500250025/training/cp.ckpt\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 2404s 161s/step - loss: 0.5511 - accuracy: 0.7293 - val_loss: 0.5177 - val_accuracy: 0.7530\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 2425s 162s/step - loss: 0.5568 - accuracy: 0.7146 - val_loss: 0.5041 - val_accuracy: 0.7660\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 2405s 161s/step - loss: 0.5309 - accuracy: 0.7412 - val_loss: 0.5103 - val_accuracy: 0.7760\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 2401s 160s/step - loss: 0.5258 - accuracy: 0.7429 - val_loss: 0.5314 - val_accuracy: 0.7410\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 2403s 161s/step - loss: 0.5102 - accuracy: 0.7570 - val_loss: 0.4980 - val_accuracy: 0.7770\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 2400s 160s/step - loss: 0.5146 - accuracy: 0.7574 - val_loss: 0.4959 - val_accuracy: 0.7710\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 2395s 160s/step - loss: 0.5187 - accuracy: 0.7501 - val_loss: 0.5043 - val_accuracy: 0.7780\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 2403s 160s/step - loss: 0.5267 - accuracy: 0.7409 - val_loss: 0.5032 - val_accuracy: 0.7670\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 2180s 145s/step - loss: 0.5331 - accuracy: 0.7413 - val_loss: 0.4960 - val_accuracy: 0.7770\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 2162s 144s/step - loss: 0.5199 - accuracy: 0.7593 - val_loss: 0.4904 - val_accuracy: 0.7750\n",
      "\n",
      "Epoch 00040: saving model to /mnt/MD1200A/lconcha/videos/Modelos/256x256_blackwhite_dropout_00500250025/training/cp.ckpt\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 2153s 144s/step - loss: 0.5308 - accuracy: 0.7348 - val_loss: 0.5008 - val_accuracy: 0.7770\n",
      "Epoch 42/50\n",
      " 6/15 [===========>..................] - ETA: 21:14 - loss: 0.5228 - accuracy: 0.7582"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"Adam\", loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#####CHECK POINTS\n",
    "checkpoint_path = \"/mnt/MD1200A/lconcha/videos/Modelos/256x256_blackwhite_dropout_00500250025/training/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 period = 10,\n",
    "                                                 verbose=1)\n",
    "\n",
    "\n",
    "history = model.fit_generator(generator=training_generator,\n",
    "                    steps_per_epoch= int((len(h5py.File(train_samples))/2))// batch_size,\n",
    "                    epochs=50,\n",
    "                    callbacks=[cp_callback],\n",
    "                    verbose=True,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=int((len(h5py.File(test_samples))/2))// batch_size,\n",
    "                    use_multiprocessing=False,\n",
    "                    workers=0,\n",
    "                    max_queue_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "correct-thought",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2aac2beea0d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"/mnt/MD1200A/lconcha/videos/Modelos/256x256_blackwhite_dropout_00500250025/training/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "completed-labor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cm/shared/apps/anaconda2/4.3.1/envs/jupyter3.7/lib/python3.7/site-packages/ipykernel_launcher.py:9: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  if __name__ == '__main__':\n",
      "/cm/shared/apps/anaconda2/4.3.1/envs/jupyter3.7/lib/python3.7/site-packages/ipykernel_launcher.py:14: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  \n",
      "/cm/shared/apps/anaconda2/4.3.1/envs/jupyter3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "/cm/shared/apps/anaconda2/4.3.1/envs/jupyter3.7/lib/python3.7/site-packages/ipykernel_launcher.py:58: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15/15 [==============================] - 2175s 145s/step - loss: 0.4936 - val_loss: 0.4923\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 2149s 143s/step - loss: 0.5097 - val_loss: 0.4962\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 2145s 143s/step - loss: 0.4917 - val_loss: 0.5088\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 2147s 143s/step - loss: 0.4934 - val_loss: 0.6355\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 2165s 144s/step - loss: 0.4836 - val_loss: 0.6208\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 2157s 144s/step - loss: 0.4850 - val_loss: 0.5930\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 2148s 143s/step - loss: 0.4889 - val_loss: 0.5935\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 2145s 143s/step - loss: 0.4851 - val_loss: 0.5531\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 2193s 147s/step - loss: 0.4755 - val_loss: 0.5276\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 2199s 147s/step - loss: 0.4716 - val_loss: 0.6055\n",
      "\n",
      "Epoch 00010: saving model to /mnt/MD1200A/lconcha/videos/Modelos/256x256_blackwhite_dropout_00500250025/training/cp.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 period = 10,\n",
    "                                                 verbose=1)\n",
    "\n",
    "\n",
    "history = model.fit_generator(generator=training_generator,\n",
    "                    steps_per_epoch= int((len(h5py.File(train_samples))/2))// batch_size,\n",
    "                    epochs=10,\n",
    "                    callbacks=[cp_callback],\n",
    "                    verbose=True,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=int((len(h5py.File(test_samples))/2))// batch_size,\n",
    "                    use_multiprocessing=False,\n",
    "                    workers=0,\n",
    "                    max_queue_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "geological-joshua",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-61b0f106842b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "model.history.history['val_loss']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
